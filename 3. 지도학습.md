연세대학교 노알버트 교수 
#lgaimers 
# Part 1. Supervised Learning Overview
![](Pasted%20image%2020250107150124.png)
![](Pasted%20image%2020250107150239.png)

이미지가 x, airplane이 y 
머신러닝 : 다양한 데이터와 정답 쌍을 주고 알고리즘이 스스로 규칙을 판단하게 끔 도와주는 것 supervised learning

## 1. classification (분류)
: 이 이미지가 10개의 카테고리 중 무엇이겠느냐를 다룰 때
![](Pasted%20image%2020250108143736.png)
## 2. 회귀(Regression)
: 정답이 숫자로 혹은 연속적인 실수 변수로 표현되는 경우 

+) 그렇다면 다음 문장에서 다음 단어를 맞추는 문제는 분류 or 회귀? --> 보통은 분류로 생각함. 

![](Pasted%20image%2020250108150639.png)

: 내가 만드는 모델이  정답 함수랑 같아야 한다.(목표가 같아지는 것)
![](Pasted%20image%2020250109151526.png)

: Pointwise loss : (x(i), y(i))라고 하는 하나의 데이터 포인트에 대해서 어떠한 손실이 발생하는지 계산한 것 
: Loss function = x(i)를 보고 내 모델이 생각하는 결과 g(seta)랑 정답 함수 f^* 가 얼마나 비슷한지를 정의한 것 
![](Pasted%20image%2020250109151927.png)

: 우리에게는 총 n개의 데이터셋가 주어져있고, 이 데이터 셋이 모사하는 함수를 찾고 싶은데,  이 함수를 세상에 존재하는 모든 함수가 아닌 함수 클래스 g를 정의해서 이 클래스 안에 있는 함수 중에서 무엇이 제일 훌륭한지 선택. 
: 무엇이 가장 훌륭한가? : L를 보고 선택

예시) 선형 회귀 예시 
![](Pasted%20image%2020250109152456.png)

: 키-몸무게라고 치면, ax+b꼴로 나타낼 수 있음. => 선형함수로 좁힘
: Loss 정의하기, 
#MSE : Mean-Squared Error(MSE)
![](Pasted%20image%2020250109152812.png)
![](Pasted%20image%2020250109153010.png)
![](Pasted%20image%2020250109153216.png)


# Part 2. Linear Regression 
#선형회귀 
## 1. 선형회귀란 무언인가? 
![](Pasted%20image%2020250109164936.png)

: x = (x1, x2) : 입력이 2개가 주어진다면 ex) 키와 손 사이즈가 주어진다면
: $$x \in X \in R^2$$ : x1과 x2를 선형 조합하는 클래스를 정의하게 된다. 
: g = a1x1+a2x2+b 로 나타낼 수 있음 
: Loss function = ()^2 으로 나타낼 수 있음 

+) 변수가 3개가 된다면 가능할 것인가? 
![](Pasted%20image%2020250109165430.png)

: 복잡한 식이 되겠지만 가능하다.

+) 복잡한 식이지만 난이도가 올라가지는 않는다. ![](Pasted%20image%2020250109165652.png)
![](Pasted%20image%2020250109170037.png)
![](Pasted%20image%2020250109170349.png)

를 수학적으로 간단한 형태로 만들어보자 
![](Pasted%20image%2020250109170430.png)
![](Pasted%20image%2020250109171007.png)

## 2. 만약 우리가 2차 함수를 맞추고 싶다고 하면 어떻게 할까? 
![](Pasted%20image%2020250109171158.png)

: 직선으로 표현을 하게 되면 , 그래프의 동그라미 친 부분들은 잘 설명하지 못하는 형태가 되어버림 
: 그렇다면 2차 함수로 표현하면 좋지 않을까? 
![](Pasted%20image%2020250109171240.png)
![](Pasted%20image%2020250109171540.png)

: 그렇다면 더 고차함수가 더 잘맞추는걸까? 
![](Pasted%20image%2020250109171638.png)

: 표현력이 높은 함수를 구현할 수는 있지만 이건 overfitting이 될 수 있으니 조심해! 
: 너무 많은 피처 혹은 너무 많은 커널들을 추가해서 더 복잡한 함수로 표현하려고 하면 overfitting이 일어난다. 
![](Pasted%20image%2020250109171918.png)

: 만약 사용자가 키와 입력을 바꿔서 적어서 그래프의 한 점을 수정해야 될 경우에도, 이 모델은 여러 개의 데이터 중에 하나가 바뀌었을 뿐이기 때문에 모델이 어마어마한 큰 차이가 발생하지 않아야된다 -> Consistency(일관성)-driven model(일관성을 유지하는 것이 중시하는 모델), Robust model(강건한 모델, 외부 환경 변화나 예기치 않은 입력에도 성능이나 안정성이 크게 떨어지지 않는 모델)
![](Pasted%20image%2020250109173824.png)

: 파란색에서 초록색으로 데이터가 바뀌면 전체적인 틀은 바뀌지 않는 것을 확인할 수 있다. 
: 그렇다면 7차식으로 피팅한다면? 
![](Pasted%20image%2020250109173947.png)

: 데이터에 과하게 피팅 되어 있는 느낌이 든다. 
: ![](Pasted%20image%2020250109174022.png)

: 한점에서 다음 점으로 이동할때(사실 내키는 170이 아니라 180이었어) 1차식은 크게 차이가 없는 선형 회귀 결과로 보이지만,  7차식(노란색)은 하나의 데이터 포인트만 바뀌었을 뿐인데, 모델은 드라마틱하게 변하는 모습을 확인할 수 있다. 
	=> 데이터에 지나치게 맞춰진 Overfitting 문제다 
 :  그래서 우리는 주어진 데이터 대비 내 모델이 지나치게 복잡하진 않는가? 내 모델의 복잡도 대비 데이터는 충분히 확보되어 있는가를 반드시 조심하는 것이 중요하다. 

## 3. 적절한 양의 데이터가 준비되어있을 때, 얼마 정도로 복잡한 모델을 사용하는 것이 좋을까? 
![](Pasted%20image%2020250109175747.png)
![](Pasted%20image%2020250109180314.png)

: 10개의 데이터를 랜덤하게 분류한 뒤, 데이터를 다 사용하지 않고 7개만 학습에 사용했을 때, 이 모델이 범용적으로 잘 되고, 데이터에 특별하게 Overfitting이 되어 있지 않다고 한다면
	=> 7개의 데이터를 가지고 계산하는 손실과 3개의 데이터를 가지고 계산하는 손실(Validation Loss)의 차이가 크지 않을 것이다. 
1. step 1. data를 train data와 validate data로 나눈다. 
2. step 2. 학습 데이터의 Loss가 유의미하게 줄어드는지 관측한다. 
   => 줄어들지 않는다면 모델이 충분히 복잡하지 않아서 Underfitting이 일어나는 경우이다.
3. step 3. 학습 데이터의 Loss가 꽤 작아지는 지점을 찾았을 때, 그때는 과적합이 발생했는지 안했는지 판단해야한다. 

+) #일반화능력 : 모델이 학습 데이터에 과도하게 의존하지 않고, 새로운 데이터(테스트 데이터)에서도 높은 성능을 발휘 할 수 있는 능력

![](Pasted%20image%2020250109181008.png)

: 대부분은 80대 20으로 나눔
: 발표할 때는 train-val이 아닌 다른 종류의 데이터를 가지고 발표해야한다. 

## 4. 애매한 경우라면? 2차식? 3차식? => Occam's Razer
![](Pasted%20image%2020250109181158.png)

: 2차식도 괜찮고 3차식도 괜찮다면 오캄의 법칙에 따라 더 간단한 모델을 선택하는 것이 맞다. 

## 5. Overfitting이라면? 
![](Pasted%20image%2020250109181658.png)

: 가능하다면 데이터를 더 얻어라 => 비쌈
: #CrossValidation 
	: 데이터가 적은 것이 고민일 때, 데이터를 80%만 학습하고 20%만 남겨두는 것은 아까울 수 있다. ![](Pasted%20image%2020250109181833.png)
	: 학습과 검증을 번갈아서 진행하면, 결과적으로 데이터를 전부 다 사용할 수 있는 테크닉 
: #Regularization 
	: #정규화
	![](Pasted%20image%2020250109182330.png)
	
	: 우리가 원한는 것은 Loss를 줄이는 건데, Overfitting이라는 것은 이 손실을 줄이는 것에만 너무 매몰되어 있는 이러한 문제 떄문에 발생하는 현상임. 
	: 얘를 차분하게 만들기 위해서 무게 추를 달아주는 거라고 말할 수 있음. 
	: 람다(a)^2 를 추가해서, Loss가 커지는 것보다 a가 커지는 것을 더 경계하는 형태
		람다가 커진다? = a가 커지는 것을 더 경계하겠다. 

: 데이터를 많이 생성하는 방법 (더 쉽고 값 싸게!)
	: #데이터증강 #Augmentation ![](Pasted%20image%2020250109182553.png)
	
	: 강아지를 좌우반전시켜도 강아지는 강아지니까! 
	: 매번 먹히는 건 아님. 숫자는 좌우반전시키면 더이상 숫자 2가 아니니까!
![](Pasted%20image%2020250109182810.png)

# Part 3. Gradient Descent 
#경사하강법 
: 지도학습에서 범용적으로 사용 가능함. 
![](Pasted%20image%2020250109192439.png)

: 누가 최소인지 어떻게 찾을까? 
	미분해서 0인 값들을 찾아낸 다음에 누가 최소인가를 확인하는 과정을 거쳤음
	=> Gradient Descent 얘도 똑같음 기울기가 0이 되는 지점을 찾는 거임. 
: Gradient Descent 에서 몇 가지 가정하는 사안. 
	1. 우리가 함수의 Gradient는 안다고 생각하는 것. 
	   : 기울기 뿐만 아니라 함수 F까지 안다고 가정함.
	2. 하지만 함수의 전체적인 그림은 볼 수 없다고 가정. (dose not have global view)
	   => 그래서 우리가 할 수 있는 건 slope(경사)를 따라 걸어내려갈 수 밖에 없는 것
: 임의의 한 점에서 낮은 곳으로 내려간다고 생각하면 됨 
![](Pasted%20image%2020250109195901.png)
 ![](Pasted%20image%2020250109195952.png)
 
 : 초기값을 0으로 잡음. 이유는 없음 다른 값으로 해도 됨. 
 : 0이라는 위치에서 슬로프를 계산해서 다음 포인트를 얻고 또 계산해서 다음 포인트를 얻고 이걸 반복하는 거임. 
 : 알파는 learning late
 : ![](Pasted%20image%2020250109200117.png)
 
 : #LearningRate : 어떤 보폭으로 이동할 것인가? 
 ![](Pasted%20image%2020250109200309.png)
 
 : 작은 learning rate는 계산이 오래 걸린다.![](Pasted%20image%2020250109200340.png)
 
 : 너무 큰 learning rate는 정확한 값을 얻을 수 없다. 
 
 : 2차원에서의 Gradient descent![](Pasted%20image%2020250109200641.png)
  
: 2차원 입력을 받는 함수. 
  : 빨간선은 한점에서 가장 빠르게 감소하는 방법을 나타냄.
  : 왼쪽의 learning rate 가 0.05 오른쪽이 0.01
  
  : 더 복잡한 경우, 실제로는 고차원이 이렇게 생기지 않았을 수도 있는데, 나타낸 것. 입력이 많은 경우 
  ![](Pasted%20image%2020250109200911.png)
 
  : gradient를 계산하는 것은 어렵지 않다. 
  : 여러 변수가 동시에 0이 나오는 것을 풀려고 하면 복잡해짐.
  : 초록색으로 표시된 곳이 최소값을 나타냄
  : 한 포인트에서 더 낮은 지대로 가다가 보면 어떤 분지에 갇히게 됨. 거기가 최소값인거임. 
  : gradient descent는 우리는 보다 작은 값으로 데려갈 수 있지만, 그 지점이 반드시 최솟값이라는 보장이 없다, 
  : 같은 함수에 대해서도 초기값이 달라짐에 따라 굉장히 드라마틱하게 수렴하는 지점이 달라질 수 있다는 것을 보여주는 예시이다. 

![](Pasted%20image%2020250109201247.png)

: 그래서 gradient descent를 할 때, 랜덤하게 초기값을 잡는 방법을 사용한다. 
: loss를 보고 learning rate를 늘리고 줄이는 것도 방법이 될 수 있다. 

![](Pasted%20image%2020250109201401.png)
![](Pasted%20image%2020250109201632.png)

: 그래서 경사하강법으로 우리가 풀고 싶은 것 : Loss들의 합이 최솟값이 되는 지점을 찾는 것. 
: 모든 데이터 포인트들에 대해서 계산은 할 수 있음. 근데 비용이 많이 들어감. 
: 실제로는 다른 방법을 씀.
	: #SGD (Stochastic Gradient Descent) : 확률적 경사하강법 
		![](Pasted%20image%2020250109201743.png)
		
		: 반복문에서 데이터를 한 개 뽑는 것을 말함. 
		: n개의 데이터 셋이 있을 때, 한 iteration에서 n개의 gradient 평균을 내는 것이 아니라 데이터를 하나 랜덤하게 뽑고 하나로 뽑은 데이터의 gradient를 이번 iteration의 gradient로 사용하는 것
		: 다시말해, 원래대로라면 전체 gradient 평균을 사용했어야 하는데, i번째 데이터 포인터에서 계산된 gradient를 대표로 대신 사용하는 것.
		--> 이게 #뭔소리 임??
		 : 실제 gradient descent를 사용하지 않기 때문에 잡음이 있는 형태의 행동을 보일 수 있다는 단점이 있다. 
		 : but, 계산이득이 있지. 1번만 계산하면 되니까 
	: Mini-batch Gradient Descent 
		![](Pasted%20image%2020250109202427.png)
		: 실제로는 이걸 가장 많이 씀.
		: 데이터를 small-b개 뽑는 것. 
: 그래서 선형 회귀에서 gradient descent를 적용한다면? 
![](Pasted%20image%2020250109202604.png)

: 근데 세상에 모든 함수가 다 아름답게 생긴건 아님. 
![](Pasted%20image%2020250109202727.png)
	
	: 이렇게 생긴 함수에서 저 많은 장애물들을 비켜가서 화살표로 표시된 최솟값(local minima, 국소최솟값)에 도달할 수 있겠는가? 
	: 어쩌면 평평한 지대에 갇혀서 도달하지 못할 수도 있음. 
	: 그래서 gradient descent는 무적은 아님. 

: 그러면, 평평한 지대에 갇히지 않게 "관성"을 부여하면 되는거 아님? 
=> Momentum SGD #MomentumSGD
![](Pasted%20image%2020250109203039.png)

: 매 지점에서 가파른 방향으로 나아가는 것이 아니라, 마치 산등성이에서 공을 굴리는 것 같은 느낌을 생각하면 됨. 
: 약간은 오르락내리락하다가 수렴하는 형태 
: 그 지점만 고려하는 것이 아니라, 내가 이전에 어떠한 궤적으로 걸어왔는지를 판단해서 다음에 어디로 갈지를 생각하는 형태가 된다. 
![](Pasted%20image%2020250109203506.png)

: 베타가 작으면 작을 수록 현재 값에 의존하는 형태 

: 관성을 주거나 SGD를 교정하는 다양한 방법
![](Pasted%20image%2020250109203605.png)

: #RMSProp : 방향들에 대해서 차별화하겠는 방식. 
	: 매개변수의 업데이트 크기를 최근의 그래디언트 크기를기반으로 조정 
	: 2차원 모멘텀을 생각하는 형태 

: #ADAM 
![](Pasted%20image%2020250109203942.png)
	
	: 실제로 가장 많이 쓰는 방식. 
	: gradient의 1차원적인 모멘텀, 2차 모멘텀을 동시에 사용하는 방식
	: Bias correction이라고 하는 테크닉을 이용해서 발생하는 약간의 편향을 교정한 다음에 이것을 이용해서 일차 모멘텀 나누기 이차 모멘텀을 해서 현재 나아가야하는 방향을 알아내는 방식. 

: Learning rate scheduling 
![](Pasted%20image%2020250109204159.png)
	: ex) learning rate가 목적지에 다다르면 다다를수록 더 작게 만들거나, 일정 epoch동안 발전이 없으면 learning rate를 더 키울 수도 있다. 


# Part 4. Classification 
#classification
## 1. #BinaryClassification
![](Pasted%20image%2020250110161414.png)

: class가 2개만 주어질 때 
![](Pasted%20image%2020250110162142.png)
![](Pasted%20image%2020250110163902.png)

: a^T x + b 가 0보다 크냐 작냐에 따라 1이냐 -1이냐로 나눔 
: #0-1Loss : 분류를 데이터 포인트에 대해서 할 때, 정답을 맞췄는지 못 맞췄는지 카운팅하는 함수 

- 선형적으로 분리가 가능한 경우에 데이터를 올바르게 분류하는 직선 분류기 알고리즘
  : #PerceptronAlgorithm #Perceptron ![](Pasted%20image%2020250110164517.png)
  
  : 데이터가 존재할 때, 임의로 직선을 긋고, 그 다음 데이터를 잘 못 분류한 포인트를 기준으로 a, b값을 업데이트하는 과정을 여러번 반복하면 올바른 값으로 수렴한다. 
  ![](Pasted%20image%2020250110164559.png)
  
  : 장점 
	  : 과정이 단순함
	  : 반드시 100% 분류가 가능한 점이 있다고 가정한다면 무조건 수렴하는 알고리즘임.  
  : 단점
	  : 세상에 어떤 것도 100% 분류가 가능하지는 않음. 
	  : 그래서 이 알고리즘은 영원히 멈추지 않고 동작하게 된다는 단점이 발생함. 

: #LinearProgramming 
![](Pasted%20image%2020250110171043.png)
![](Pasted%20image%2020250110171631.png)


: 최적화 : 최소화 혹은 최대화하고 싶은 어떤 대상이 있다면, 최소화 혹은 최대화를 하는 동안 만족해야 하는 어떤 조건이 존재하게 된다.
: sgn과 내 y가 같아야 한다. => 조건
: subject to를 보면 (axi+b)가 음수면 yi가 음수여야하고, 양수면 양수가 되어야 하는 식. => 조건
: 목표는 없지만 조건은 있는 형태의 최적화 문제를 푸는 그런 상황 
: 장점
	: 정답이 없는 경우에는 솔루션이 존재하지 않는다는 것을 알려줌. 
: 단점
	: 존재하는 정답 중에 정확하게 어떤 것을 주는 건지 알 수 없다. 
	: ![](Pasted%20image%2020250110172426.png)
	: 
	어떤 모델을 선택하는 것이 옳은가? (초록색인지, 검정색인지) -> margin이 큰 모델을 선택하겠다. -> 각 점으로부터 거리가 큰 모델을 선택하겠다. ![](Pasted%20image%2020250110172549.png)
	: 
	초록색 선이 margin이 작은 모델
	: margin이 더 큰 모델을 더 견고하다고 표현하고 그걸 선택하는게 옳다. 

## 2. #SVM 
: 주어진 데이터를 두 class로 나누는 초평면(hyperplane)을 찾는 것. 
: 이 초평면은 데이터를 최대한 잘 구분할 수 있도록 설명되며, 이는 margin을 최대화하는 것을 뜻함.
: ![](Pasted%20image%2020250110173536.png)

: a^Tx0 +b를 1로 고정을 한 상태였을 때, a가 가장 작아졌을면 좋겠다 라는 식으로 조건을 바꾸어서 역으로 푸는 것을 SVM이라고 한다. 
: 즉, a^Tx0 +b의 margin이 1로 유지된 상태에서 분모에 해당하는 a의 크기가 가장 작아지면 결론적으로 margin의 값이 커지니까! 
![](Pasted%20image%2020250110173821.png)

: #QCQP (Quadratically Constrained Quadratic Program)
	: 2차 제약 조건(Quadratic Constraints)과 2차 목적 함수(Quadratic Objective Function)를 포함하는 최적화 문제

## 3. 데이터가 선형적으로 분리되지 않은 경우가 더 많음
: ![](Pasted%20image%2020250110174101.png)

: 이런 경우가 더 많음. 
: 근데 이런 경우도 SVM을 사용해서 풀고 싶잖아? 
=> #SlackVariable 을 추가하여 해결할 수 있다. 
![](Pasted%20image%2020250110174231.png)

: 올바르게 분류되면서 margin이 1이상이어야 한다는 것을 제약 조건으로 삼았다고 생각하면 됨. 
: 모든 점이 만족할 수 없다면, 각 점마다 제타i만큼의 패널티를 추가하여 만족할 수 없다면 그나마 조금 넘어라 라는 조건을 추가할 수 있다. 
: 제타가 0이면 가장 좋지. #HingeLoss
![](Pasted%20image%2020250110174603.png)

## 4. 데이터가 직선으로 분류하는 것이 불충분하다면? 
#kernel
![](Pasted%20image%2020250110174811.png): x1, x2, x1^2, x2^2를 넣어줌으로써 2차 타원의 형태를 표현할 수 있기 때문에, 더 잘 표현할 수 있게 된다. 
: overfitting이 발생 할 수 있다

# Part 5. Logistic Regression 
#LogisticRegression
: 이진 분류에서 벗어나 여러 클래스가 존재한다면 어떻게 해결할까? 

## 1.  Soft guess
#Softguess 
: ![](Pasted%20image%2020250110180510.png)
: 어떤 이미지에 대해서 이건 강아지야, 이건 고양이야 라고 나눌 수 있다면 -> hard guess 
: 강아지인 것 같기도, 고양이인 것 같기도 -> soft guess 
	: 이런 경우 억지로 하나를 고르게 하는 것보다, 강아지일 확률, 고양이일 확률을 나누는 것이 나중에 구별 가능하고도 연결되는 포인트가 된다. 
	: 확률로 나누고 나중에 사람한테 결정하라고 할 수도 있음. 
	
![](Pasted%20image%2020250110180828.png)
: 숫자 2개를 내뱉는 모델이 된다. ![](Pasted%20image%2020250110180933.png)
![](Pasted%20image%2020250110181104.png)
: #CrossEntropyLoss : 정답에 얼마나 가깝게 접근했냐 ![](Pasted%20image%2020250110181301.png)

: crosse entropy loss는 #KL 에서 유도가 되었음 
#Kullback-LeiblerDivergence , #RelativeEntropy: 2개의 확률분포가 주어질 때, 이 2개가 확률 분포가 얼마나 멀리 떨어져 있는가를 계산하는 확률 분포 사이의 거리를 측정하는 함수
	: ex) 비가 올 확률이 30%(p), 비가 오지 않을 확률 70%(q)라면 식이 저렇게 됨. 


![](Pasted%20image%2020250110181933.png)

: 데이터가 n개 주어져 있을때, 
: y가 -1일 확률과, 1일 확률을 로지스틱 함수를 이용해서 표현하는 함수 클래스를 정의한다. 
: Loss function : cross entropy를 이용해서 정답에 얼마나 높은 확률로, 혹은 낮은 확률로 예측했는가를 평가하는 형태로 손실을 계산하게 한다. 

![](Pasted%20image%2020250110182214.png)
![](Pasted%20image%2020250110182429.png)
![](Pasted%20image%2020250110182555.png)

## 2. Multiclass Classification
#MulticlassClassification 
![](Pasted%20image%2020250110183509.png)

: 강아지일 확률, 고양이일 확률, 비행기일 확률을 내뱉는 모델을 디자인할 수 있음. 
: 방법 : Linear 함수를 통과 -> Softmax 함수 통과(확률과 유사한 산출물을 내도록 함수를 설정)

## 3. Softmax Function
#softmax 
![](Pasted%20image%2020250110201725.png)

: max 함수를 hard하게 max를 찾는 것이 아니라 soft하게 max를 찾는 값 
: softmax의 산출물을 다 더하면 1이 되고, 각각은 모두 양수

![](Pasted%20image%2020250110202459.png)

: softmax regression이 logistic regression을 포함하는 관계이다

![](Pasted%20image%2020250110202702.png)
![](Pasted%20image%2020250110202856.png)

: d : x에 대한 입력 차원 
: k : class의 개수 
: loss : cross entropy 사용 

: ex) 코로나 검사기
![](Pasted%20image%2020250110203020.png)

: 코로나냐 아니냐를 판단할 때, 우리는 확률이 50%가 넘으면 코로나라고 보고 아니면 코로나가 아니라고 판단하는 경향이 있다. 
: 근데 조금이라도 코로나라고 판단이 된다면 빨리 알려줘서 공공의 이익에 더 도움이 되잖아? 그러면 추가적인 검사를 진행하는 것이 더 옳을 수 도 있음 
: 코로나 환자를 놓치는 것이 더 두려운 상황 
: 그래서 기준점을 20%로 보고 20% 이상은 잠재적인 코로나 환자라고 분류하는 기법도 가능하다. 
==> 결론 : threshold는 경우에 따라 더 높게 잡을 수도 더 낮게 잡을 수도 있다. 
: 단점 : 코로나가 아닌 사람을 코로나라고 분류할 수도 있음. 
: precision : 우리가 양성이라고 판단한 사람 중에 진짜 양성 환자는 어느 정도 였냐? 
: recall : 실제 양성 환자 중에 우리가 얼마나 양성 판정을 내렸냐 
(두 개가 상반되는 개념, trade-off가 일어남)

: 어느 것을 더 중점을 두겠느냐? -> #F1-score ![](Pasted%20image%2020250110203703.png)

: #ROCCurve
![](Pasted%20image%2020250110203725.png)

: True Positive Rate : 실제 positive인 것 중에 내가 True positive를 얼마나 많이 선언했는가? 
: False positice rate : 실제 negative 중에 우리가 false positive를 얼마나 많이 얘기 했는가?
: treshold가 변함에 따라 어떻게 변하는지 보여주는 그래프
: 아래 면적이 넓을수록 더 좋은 알고리즘이다. -> 그래서 어떤 지표로 많이 쓰이는 경우도 있다. 



# Part 6. More On Supervised Learning Beyond 
: 전통적으로 사람들이 시도해왔던 방법들에대한 소개를 해주신다고 하심. 

![](Pasted%20image%2020250113175838.png)

## 1. Naive Bayes : Spam Filter 
#NaiveBayers #SpamFilter
![](Pasted%20image%2020250113180004.png)

: x와 그에 대응되는 y가 있을 때
: 가장 많이 예로 많이 드는 것이 : spam filter 
	: 어떤 이메일이 올 때, 이 이메일에 주로 등장하는 단어를 5만 개라고 가정. 
	: 5만 개의 단어 중에서, 각각의 단어를 0과 1을 이용해서 표현할 수 있다.
	: 어떤 메일이 왔을 때, 그 메일이 스펨인지 아닌지를 판단하는 것이 목적. 
	: 그 메일(X)이 스팸일지(1), 스팸이 아닐지(-1)로 확률로 판단. 
	: 이 복잡한 확률을 간단하게 만들기 위해서, 단순한 가정을 하게 된다. 
		=> #나이브베이즈 가정 
		: X의 벡터들이 어떤 Y가 주어졌을 때 독립이라는 가정 , 각 단어가 등장하거나 등장하지 않을 확률이 전부 독립이라는 것. 
		: 그걸 식으로 표현하면 저렇게 됨. 
	![](Pasted%20image%2020250113184128.png)
	
	: 
	 전체 메일이 10000개 일 때, 그 중 스팸 메일이 5000개고, 그 중에서 J번째 단어를 포함한 것이 몇 개 있는지를 세기만 하면 확률은 알 수 있음. 
	: 이런 식으로 y가 1일 때의 j번째 단어의 빈도와 스팸 메일이 아닐 때의 빈도를 계산하고, 스팸 메일의 비율을 계산하면, 최종적으로 확률의 역산을 베이즈 정리를 이용해서 진행을 할 수 있게 된다. 
	![](Pasted%20image%2020250113184501.png)
	:
	나이즈 베이즈드 방법을 사용할때
	장점 : 
		1. 조건부 독립이라고 하는 가정이 현실과 맞지 않을 수 있지만, 그럼에도 불구하고 합리적으로 작동한다. 
		2. 이 결과가 해석 가능하다. 
	문제점 : 
		1. 한번도 나오지 않은 단어를 해석할 때, 우리가 어떻게 받아들여야하는가? ![](Pasted%20image%2020250113184842.png)
		   
: 예를 들어, 35000번째 단어는 어떤 메일이도 등장하지 않았다고 가정. 
		   그 경우에는 우리가 이 확률을 0으로 추정할 수 밖에 없는데, 사실확률이 0인 것은 이 단어를  한 번도 못 봤기 때문이지 이 단어가 스팸이냐 스팸이 아니냐를 결정하는데 어떠한 영향을 줬는지 안 줬는지 전혀 모르는 상황에서 이런 평가를 내리는 것이 부당하다. 
		   ==> 이걸 해결하는 방안으로 나온 것이 'laplace smoothing'
## 2. Naive Bayes : Laplace Smoothing 
#LaplaceSmoothing 
![](Pasted%20image%2020250113185135.png)

:
각 단어마다 스펨 메일에서는 얼마나 나왔는지, 스팸 메일이 아닌 것에서는 얼마나 나왔는지 비율을 추산할 때, 모든 단어가 이미 한 번씩 등장했다고 가정. 
=> 0이 발생하는 것을 방지 

## 3. Decision Tree
#DecisionTree
![](Pasted%20image%2020250113185356.png)

:
해석 가능한 변수들을 이용해서 이 모델을 해석할 수 있다. 
: but, 스스로 학습하는 건 조금 부족함. 
=> 성능이 복잡한 과제에서는 떨어질 수 있다
 ![](Pasted%20image%2020250113185649.png)

: 의사결정나무는 분류뿐만 아니라 회귀문제에서도 쓸 수 있다.![](Pasted%20image%2020250113185825.png)

![](Pasted%20image%2020250113185938.png)

: 이 질문을 했을 때 분할이 얼마나 균일하게 분산이 발생하는지를  엔트로피와 같은 방법으로 측정해서 질문을 선택할 수 있다. 

: 집값과 같이 어떤 특정한 값을 예측해 내야 하는 경우에는 각 leaf마다 분산이 적어서 내 추정치가 오차가 적도록 하는 그러한 형태의 분할 기준을 선택하는 것이 효율적이다. 

## 4. Bagging 
#Bagging 
: 여러 개의 트리를 사용해서 종합적으로 앙상블 모델이라는 기법을 이용해서 평가하는 방법 
![](Pasted%20image%2020250113190249.png)
## 5. Random forest 
#RandomForest

![](Pasted%20image%2020250113190318.png)

: 1,3 의사결정나무에서는 포유류라고 하고, 2번에서는 포유류가 아니라고 하면 이 동물을 포유류라고 결론짓는 것. 
: 몇몇 트리가 잘못된 판단을 하더라도 대다수의 트리가 제대로된 판단을 한다면 성능이 올라가는 형태 
: 회귀에서는 3개의 평균으로 판단을 내릴 수 있음. 

## 6. Adaptive Boosting(AdaBoost)
#AdaBoost #AdaptiveBoosting
: 앙상블 기법 
: 여러 개의 모델을 순차적으로 학습시킴
: 첫번째 모델을 학습을 해서 테스트를 했을때, 잘못 분류하는 친구들에게는 더 많은 가중치를, regression 문제라고 한다면 더 오차가 큰 친구들한테는 더 높은 가중치를 줘서 그 다음 학습할때는 그 모델을 위주로 학습을 하도록 만드는 것. 

![](Pasted%20image%2020250113190843.png)

- Bagging과 Boosting의 차이점 
: bagging은 평행으로 학습을 시켜 분산을 줄일 수 있다. 
: Boosting은 성능이 좋아지지만 역시 과적합의 문제가 발생할 수 있다. 

![](Pasted%20image%2020250113191034.png)

: #SuperResolution : 저해상도의 이미지를 고이미지로 만드는 문제 
: (저해상도 이미지, 고해상도 이미지)로 트레이닝해서 해결할 수 있다. 

![](Pasted%20image%2020250113191214.png)

: #ObjectDetection : 이미지의 위치, 이미지가 무엇인지 
: Loss는 classification loss 혹은 cross entropy loss와 같은 형태로 평가할 수 있다. 

#BERT
![](Pasted%20image%2020250113191432.png)
: 언어모델
: 어떤 문장이 주어졌을 떄, 특정 단어를 마스킹 처리한다. 
: 마스크 되어 있는 단어를 잘 표현했는지 안됐는지 처리? 
: 트랜스포머로 풀 수 있음 

![](Pasted%20image%2020250113191610.png)

: 두 문장을 주고 두 문장이 이어지는 문장인지를 물어는 문제 
: 2 문장이 입력으로 들어가고, 출력은 이진 분류 yes or no로 푸는 task가 된다. 
: 이것도 트렌스포머 기반 모델

#AnomalyDetection ![](Pasted%20image%2020250113191757.png)

: 센서로 부터 입력을 받아서 이상 상황인지 아닌지 판단하는 task 
: 학습을 통해 이상한 상황이니까 무엇인가 대비를 해야 된다고 하는 것을 가능 

## 7. 준지도 학습 
#SemiSupervisedLearning
![](Pasted%20image%2020250113192035.png)

: 정답 레이블을 하나하나 사람이 찾아주는건 시간이 오래 걸릴 수 있다. 
: 이런 문제를 해결하기 위해서, 데이터가 많지만 대부분은 y가 없음. 
: 레이블이 없는 데이터를 통해 데이터의 특성을 배우고, 그 다음에 추출된 특성으로부터 효율적으로 적은 데이터로 분류하는 기법을 배운다. 
: 레이블이 없는 데이터로부터 어떻게 특성을 배울까? 
	=> #증강기법 사용 
	![](Pasted%20image%2020250113192452.png)

: 원본 이미지로부터 증강된 이미지들을 이용
: 강아지라는 레이블이 주어져 있지 않기 때문에 어떤 특징을 추출해야될 지는 모르나, 동일한 특징을 가지고 있다는 특성을 이용할 수는 있다. 


## 8. Generative Models 
#GenerativeModels 
: 생성형 모델 
: 대표적인 준지도학습 
: 이미지가 많이 주어져있고, 이미지의 레이블은 없을 때, 과제는 이 이미지는 어떤 이미지들인가 이미지의 특성들을 학습을 해서 이 비슷한 이미지를 생성해 내야 되는 이러한 과제를 해결하는 모델을 뜻함 
: 데이터가 많이 주어져있을 때, 데이터의 분포를 파악하는 문제라고 할 수 있음. 
![](Pasted%20image%2020250113193036.png)


## 9. GAN(Generative Adversarial Networks)
#GAN #GenerativeAdversarialNetworks 
지금은 diffusion이 많이 사용되지만 , 몇 년전에는 GAN을 많이 사용했다. 
![](Pasted%20image%2020250113193615.png)

: Generator라고 하는 이미지를 생성하는 모델이랑 생성된 이미지가 진짜인지 아닌지를 판단하는 Discriminator 두 개의 파트가 서로 상호보완적으로 학습이 일어나면서 결국 generator는 더욱더 정교한 가짜 이미지를 만들고 Discriminator는 점점 더 진짜와 가짜를 효과적으로 판단하고 이 과정을 반복적으로 학습을 수행하면서 genrator의 성능을 끌어 올리는 기법 

## 10. Diffusion Models 
#DiffusionModels 
: 이미지에 노이즈를 추가해서 노이즈화 시키는 일련의 과정을 우리가 정방향 프로세스라고 부르며 
: 노이즈로부터 다시 원래 이미지를 복원해내는 디노이징 과정을 거치는 역방향 프로세스가 존재
: 각 스탭에서 노이즈를 하나 줄이면 무슨 일이 벌어지는가, 이 노이즈를 어떻게 하면 줄 일 수 있는가에 대한 학습을 수행하게됨. 
: 처음에 우리에게 주어진 이미지는 label이 없는 데이터지만 우리가 이 이미지에 노이즈를 더할 수는 있다. 그 이미지로부터 노이즈를 빼면 어떤 이미지가 나와야 하는지 우리는 정답 이미지를 알고 있게된다. 


![](Pasted%20image%2020250113194204.png)

이상. 
다양한 지도학습의 예시였음. 
비지도학습이면서 그 안에 지도 학습의 특징을 가지고 있는 모델에 대한 설명이었습니다. 