연세대학교 노알버트 교수 
#lgaimers 
# Part 1. Supervised Learning Overview
![](Pasted%20image%2020250107150124.png)
![](Pasted%20image%2020250107150239.png)
이미지가 x, airplane이 y 
머신러닝 : 다양한 데이터와 정답 쌍을 주고 알고리즘이 스스로 규칙을 판단하게 끔 도와주는 것 supervised learning

## 1. classification (분류)
: 이 이미지가 10개의 카테고리 중 무엇이겠느냐를 다룰 때
![](Pasted%20image%2020250108143736.png)
## 2. 회귀(Regression)
: 정답이 숫자로 혹은 연속적인 실수 변수로 표현되는 경우 

+) 그렇다면 다음 문장에서 다음 단어를 맞추는 문제는 분류 or 회귀? --> 보통은 분류로 생각함. 

![](Pasted%20image%2020250108150639.png)
: 내가 만드는 모델이  정답 함수랑 같아야 한다.(목표가 같아지는 것)
![](Pasted%20image%2020250109151526.png)
: Pointwise loss : (x(i), y(i))라고 하는 하나의 데이터 포인트에 대해서 어떠한 손실이 발생하는지 계산한 것 
: Loss function = x(i)를 보고 내 모델이 생각하는 결과 g(seta)랑 정답 함수 f^* 가 얼마나 비슷한지를 정의한 것 
![](Pasted%20image%2020250109151927.png)
: 우리에게는 총 n개의 데이터셋가 주어져있고, 이 데이터 셋이 모사하는 함수를 찾고 싶은데,  이 함수를 세상에 존재하는 모든 함수가 아닌 함수 클래스 g를 정의해서 이 클래스 안에 있는 함수 중에서 무엇이 제일 훌륭한지 선택. 
: 무엇이 가장 훌륭한가? : L를 보고 선택

예시) 선형 회귀 예시 ![](Pasted%20image%2020250109152456.png)
: 키-몸무게라고 치면, ax+b꼴로 나타낼 수 있음. => 선형함수로 좁힘
: Loss 정의하기, 
#MSE : Mean-Squared Error(MSE)
![](Pasted%20image%2020250109152812.png)
![](Pasted%20image%2020250109153010.png)
![](Pasted%20image%2020250109153216.png)


# Part 2. Linear Regression 
#선형회귀 
## 1. 선형회귀란 무언인가? 
![](Pasted%20image%2020250109164936.png)
: x = (x1, x2) : 입력이 2개가 주어진다면 ex) 키와 손 사이즈가 주어진다면
: $$x \in X \in R^2$$ : x1과 x2를 선형 조합하는 클래스를 정의하게 된다. 
: g = a1x1+a2x2+b 로 나타낼 수 있음 
: Loss function = ()^2 으로 나타낼 수 있음 

+) 변수가 3개가 된다면 가능할 것인가? 
![](Pasted%20image%2020250109165430.png)
: 복잡한 식이 되겠지만 가능하다.

+) 복잡한 식이지만 난이도가 올라가지는 않는다. ![](Pasted%20image%2020250109165652.png)
![](Pasted%20image%2020250109170037.png)
![](Pasted%20image%2020250109170349.png)
를 수학적으로 간단한 형태로 만들어보자 
![](Pasted%20image%2020250109170430.png)
![](Pasted%20image%2020250109171007.png)

## 2. 만약 우리가 2차 함수를 맞추고 싶다고 하면 어떻게 할까? 
![](Pasted%20image%2020250109171158.png): 직선으로 표현을 하게 되면 , 그래프의 동그라미 친 부분들은 잘 설명하지 못하는 형태가 되어버림 
: 그렇다면 2차 함수로 표현하면 좋지 않을까? 
![](Pasted%20image%2020250109171240.png)
![](Pasted%20image%2020250109171540.png)
: 그렇다면 더 고차함수가 더 잘맞추는걸까? 
![](Pasted%20image%2020250109171638.png)
: 표현력이 높은 함수를 구현할 수는 있지만 이건 overfitting이 될 수 있으니 조심해! 
: 너무 많은 피처 혹은 너무 많은 커널들을 추가해서 더 복잡한 함수로 표현하려고 하면 overfitting이 일어난다. 
![](Pasted%20image%2020250109171918.png)
: 만약 사용자가 키와 입력을 바꿔서 적어서 그래프의 한 점을 수정해야 될 경우에도, 이 모델은 여러 개의 데이터 중에 하나가 바뀌었을 뿐이기 때문에 모델이 어마어마한 큰 차이가 발생하지 않아야된다 -> Consistency(일관성)-driven model(일관성을 유지하는 것이 중시하는 모델), Robust model(강건한 모델, 외부 환경 변화나 예기치 않은 입력에도 성능이나 안정성이 크게 떨어지지 않는 모델)
![](Pasted%20image%2020250109173824.png)
: 파란색에서 초록색으로 데이터가 바뀌면 전체적인 틀은 바뀌지 않는 것을 확인할 수 있다. 
: 그렇다면 7차식으로 피팅한다면? 
![](Pasted%20image%2020250109173947.png)
: 데이터에 과하게 피팅 되어 있는 느낌이 든다. 
: ![](Pasted%20image%2020250109174022.png)
: 한점에서 다음 점으로 이동할때(사실 내키는 170이 아니라 180이었어) 1차식은 크게 차이가 없는 선형 회귀 결과로 보이지만,  7차식(노란색)은 하나의 데이터 포인트만 바뀌었을 뿐인데, 모델은 드라마틱하게 변하는 모습을 확인할 수 있다. 
	=> 데이터에 지나치게 맞춰진 Overfitting 문제다 
 :  그래서 우리는 주어진 데이터 대비 내 모델이 지나치게 복잡하진 않는가? 내 모델의 복잡도 대비 데이터는 충분히 확보되어 있는가를 반드시 조심하는 것이 중요하다. 

## 3. 적절한 양의 데이터가 준비되어있을 때, 얼마 정도로 복잡한 모델을 사용하는 것이 좋을까? 
![](Pasted%20image%2020250109175747.png)
![](Pasted%20image%2020250109180314.png)
: 10개의 데이터를 랜덤하게 분류한 뒤, 데이터를 다 사용하지 않고 7개만 학습에 사용했을 때, 이 모델이 범용적으로 잘 되고, 데이터에 특별하게 Overfitting이 되어 있지 않다고 한다면
	=> 7개의 데이터를 가지고 계산하는 손실과 3개의 데이터를 가지고 계산하는 손실(Validation Loss)의 차이가 크지 않을 것이다. 
1. step 1. data를 train data와 validate data로 나눈다. 
2. step 2. 학습 데이터의 Loss가 유의미하게 줄어드는지 관측한다. 
   => 줄어들지 않는다면 모델이 충분히 복잡하지 않아서 Underfitting이 일어나는 경우이다.
3. step 3. 학습 데이터의 Loss가 꽤 작아지는 지점을 찾았을 때, 그때는 과적합이 발생했는지 안했는지 판단해야한다. 

+) #일반화능력 : 모델이 학습 데이터에 과도하게 의존하지 않고, 새로운 데이터(테스트 데이터)에서도 높은 성능을 발휘 할 수 있는 능력

![](Pasted%20image%2020250109181008.png)
: 대부분은 80대 20으로 나눔
: 발표할 때는 train-val이 아닌 다른 종류의 데이터를 가지고 발표해야한다. 

## 4. 애매한 경우라면? 2차식? 3차식? => Occam's Razer
![](Pasted%20image%2020250109181158.png)
: 2차식도 괜찮고 3차식도 괜찮다면 오캄의 법칙에 따라 더 간단한 모델을 선택하는 것이 맞다. 

## 5. Overfitting이라면? 
![](Pasted%20image%2020250109181658.png)
: 가능하다면 데이터를 더 얻어라 => 비쌈
: #CrossValidation 
	: 데이터가 적은 것이 고민일 때, 데이터를 80%만 학습하고 20%만 남겨두는 것은 아까울 수 있다. ![](Pasted%20image%2020250109181833.png)
	: 학습과 검증을 번갈아서 진행하면, 결과적으로 데이터를 전부 다 사용할 수 있는 테크닉 
: #Regularization 
	: #정규화
	![](Pasted%20image%2020250109182330.png)
	: 우리가 원한는 것은 Loss를 줄이는 건데, Overfitting이라는 것은 이 손실을 줄이는 것에만 너무 매몰되어 있는 이러한 문제 떄문에 발생하는 현상임. 
	: 얘를 차분하게 만들기 위해서 무게 추를 달아주는 거라고 말할 수 있음. 
	: 람다(a)^2 를 추가해서, Loss가 커지는 것보다 a가 커지는 것을 더 경계하는 형태
		람다가 커진다? = a가 커지는 것을 더 경계하겠다. 

: 데이터를 많이 생성하는 방법 (더 쉽고 값 싸게!)
	: #데이터증강 #Augmentation ![](Pasted%20image%2020250109182553.png)
	: 강아지를 좌우반전시켜도 강아지는 강아지니까! 
	: 매번 먹히는 건 아님. 숫자는 좌우반전시키면 더이상 숫자 2가 아니니까!
![](Pasted%20image%2020250109182810.png)

# Part 3. Gradient Descent 
#경사하강법 
: 지도학습에서 범용적으로 사용 가능함. 
![](Pasted%20image%2020250109192439.png)
: 누가 최소인지 어떻게 찾을까? 
	미분해서 0인 값들을 찾아낸 다음에 누가 최소인가를 확인하는 과정을 거쳤음
	=> Gradient Descent 얘도 똑같음 기울기가 0이 되는 지점을 찾는 거임. 
: Gradient Descent 에서 몇 가지 가정하는 사안. 
	1. 우리가 함수의 Gradient는 안다고 생각하는 것. 
	   : 기울기 뿐만 아니라 함수 F까지 안다고 가정함.
	2. 하지만 함수의 전체적인 그림은 볼 수 없다고 가정. (dose not have global view)
	   => 그래서 우리가 할 수 있는 건 slope(경사)를 따라 걸어내려갈 수 밖에 없는 것
: 임의의 한 점에서 낮은 곳으로 내려간다고 생각하면 됨 
![](Pasted%20image%2020250109195901.png)
 ![](Pasted%20image%2020250109195952.png)
 : 초기값을 0으로 잡음. 이유는 없음 다른 값으로 해도 됨. 
 : 0이라는 위치에서 슬로프를 계산해서 다음 포인트를 얻고 또 계산해서 다음 포인트를 얻고 이걸 반복하는 거임. 
 : 알파는 learning late
 : ![](Pasted%20image%2020250109200117.png)
 : #LearningRate : 어떤 보폭으로 이동할 것인가? 
 ![](Pasted%20image%2020250109200309.png)
 : 작은 learning rate는 계산이 오래 걸린다.![](Pasted%20image%2020250109200340.png)
 : 너무 큰 learning rate는 정확한 값을 얻을 수 없다. 
 
 : 2차원에서의 Gradient descent![](Pasted%20image%2020250109200641.png)
  : 2차원 입력을 받는 함수. 
  : 빨간선은 한점에서 가장 빠르게 감소하는 방법을 나타냄.
  : 왼쪽의 learning rate 가 0.05 오른쪽이 0.01
  
  : 더 복잡한 경우, 실제로는 고차원이 이렇게 생기지 않았을 수도 있는데, 나타낸 것. 입력이 많은 경우 
  ![](Pasted%20image%2020250109200911.png)
  : gradient를 계산하는 것은 어렵지 않다. 
  : 여러 변수가 동시에 0이 나오는 것을 풀려고 하면 복잡해짐.
  : 초록색으로 표시된 곳이 최소값을 나타냄
  : 한 포인트에서 더 낮은 지대로 가다가 보면 어떤 분지에 갇히게 됨. 거기가 최소값인거임. 
  : gradient descent는 우리는 보다 작은 값으로 데려갈 수 있지만, 그 지점이 반드시 최솟값이라는 보장이 없다, 
  : 같은 함수에 대해서도 초기값이 달라짐에 따라 굉장히 드라마틱하게 수렴하는 지점이 달라질 수 있다는 것을 보여주는 예시이다. 

![](Pasted%20image%2020250109201247.png)
: 그래서 gradient descent를 할 때, 랜덤하게 초기값을 잡는 방법을 사용한다. 
: loss를 보고 learning rate를 늘리고 줄이는 것도 방법이 될 수 있다. 

![](Pasted%20image%2020250109201401.png)
![](Pasted%20image%2020250109201632.png)
: 그래서 경사하강법으로 우리가 풀고 싶은 것 : Loss들의 합이 최솟값이 되는 지점을 찾는 것. 
: 모든 데이터 포인트들에 대해서 계산은 할 수 있음. 근데 비용이 많이 들어감. 
: 실제로는 다른 방법을 씀.
	: #SGD (Stochastic Gradient Descent) : 확률적 경사하강법 
		![](Pasted%20image%2020250109201743.png)
		: 반복문에서 데이터를 한 개 뽑는 것을 말함. 
		: n개의 데이터 셋이 있을 때, 한 iteration에서 n개의 gradient 평균을 내는 것이 아니라 데이터를 하나 랜덤하게 뽑고 하나로 뽑은 데이터의 gradient를 이번 iteration의 gradient로 사용하는 것
		: 다시말해, 원래대로라면 전체 gradient 평균을 사용했어야 하는데, i번째 데이터 포인터에서 계산된 gradient를 대표로 대신 사용하는 것.
		--> 이게 #뭔소리 임??
		 : 실제 gradient descent를 사용하지 않기 때문에 잡음이 있는 형태의 행동을 보일 수 있다는 단점이 있다. 
		 : but, 계산이득이 있지. 1번만 계산하면 되니까 
	: Mini-batch Gradient Descent 
		![](Pasted%20image%2020250109202427.png)
		: 실제로는 이걸 가장 많이 씀.
		: 데이터를 small-b개 뽑는 것. 
: 그래서 선형 회귀에서 gradient descent를 적용한다면? 
![](Pasted%20image%2020250109202604.png)

: 근데 세상에 모든 함수가 다 아름답게 생긴건 아님. 
![](Pasted%20image%2020250109202727.png)
	: 이렇게 생긴 함수에서 저 많은 장애물들을 비켜가서 화살표로 표시된 최솟값(local minima, 국소최솟값)에 도달할 수 있겠는가? 
	: 어쩌면 평평한 지대에 갇혀서 도달하지 못할 수도 있음. 
	: 그래서 gradient descent는 무적은 아님. 

: 그러면, 평평한 지대에 갇히지 않게 "관성"을 부여하면 되는거 아님? 
=> Momentum SGD #MomentumSGD
![](Pasted%20image%2020250109203039.png)
: 매 지점에서 가파른 방향으로 나아가는 것이 아니라, 마치 산등성이에서 공을 굴리는 것 같은 느낌을 생각하면 됨. 
: 약간은 오르락내리락하다가 수렴하는 형태 
: 그 지점만 고려하는 것이 아니라, 내가 이전에 어떠한 궤적으로 걸어왔는지를 판단해서 다음에 어디로 갈지를 생각하는 형태가 된다. 
![](Pasted%20image%2020250109203506.png)
: 베타가 작으면 작을 수록 현재 값에 의존하는 형태 

: 관성을 주거나 SGD를 교정하는 다양한 방법
![](Pasted%20image%2020250109203605.png)
: #RMSProp : 방향들에 대해서 차별화하겠는 방식. 
	: 매개변수의 업데이트 크기를 최근의 그래디언트 크기를기반으로 조정 
	: 2차원 모멘텀을 생각하는 형태 

: #ADAM 
![](Pasted%20image%2020250109203942.png)
	: 실제로 가장 많이 쓰는 방식. 
	: gradient의 1차원적인 모멘텀, 2차 모멘텀을 동시에 사용하는 방식
	: Bias correction이라고 하는 테크닉을 이용해서 발생하는 약간의 편향을 교정한 다음에 이것을 이용해서 일차 모멘텀 나누기 이차 모멘텀을 해서 현재 나아가야하는 방향을 알아내는 방식. 

: Learning rate scheduling 
![](Pasted%20image%2020250109204159.png)
	: ex) learning rate가 목적지에 다다르면 다다를수록 더 작게 만들거나, 일정 epoch동안 발전이 없으면 learning rate를 더 키울 수도 있다. 


# Part 4. Classification 
#classification
## 1. #BinaryClassification
![](Pasted%20image%2020250110161414.png)
: class가 2개만 주어질 때 
![](Pasted%20image%2020250110162142.png)
![](Pasted%20image%2020250110163902.png)
: a^T x + b 가 0보다 크냐 작냐에 따라 1이냐 -1이냐로 나눔 
: #0-1Loss : 분류를 데이터 포인트에 대해서 할 때, 정답을 맞췄는지 못 맞췄는지 카운팅하는 함수 

- 선형적으로 분리가 가능한 경우에 데이터를 올바르게 분류하는 직선 분류기 알고리즘
  : #PerceptronAlgorithm #Perceptron ![](Pasted%20image%2020250110164517.png)
  : 데이터가 존재할 때, 임의로 직선을 긋고, 그 다음 데이터를 잘 못 분류한 포인트를 기준으로 a, b값을 업데이트하는 과정을 여러번 반복하면 올바른 값으로 수렴한다. 
  ![](Pasted%20image%2020250110164559.png)
  : 장점 
	  : 과정이 단순함
	  : 반드시 100% 분류가 가능한 점이 있다고 가정한다면 무조건 수렴하는 알고리즘임.  
  : 단점
	  : 세상에 어떤 것도 100% 분류가 가능하지는 않음. 
	  : 그래서 이 알고리즘은 영원히 멈추지 않고 동작하게 된다는 단점이 발생함. 

: #LinearProgramming 
![](Pasted%20image%2020250110171043.png)
![](Pasted%20image%2020250110171631.png)

: 최적화 : 최소화 혹은 최대화하고 싶은 어떤 대상이 있다면, 최소화 혹은 최대화를 하는 동안 만족해야 하는 어떤 조건이 존재하게 된다.
: sgn과 내 y가 같아야 한다. => 조건
: subject to를 보면 (axi+b)가 음수면 yi가 음수여야하고, 양수면 양수가 되어야 하는 식. => 조건
: 목표는 없지만 조건은 있는 형태의 최적화 문제를 푸는 그런 상황 
: 장점
	: 정답이 없는 경우에는 솔루션이 존재하지 않는다는 것을 알려줌. 
: 단점
	: 존재하는 정답 중에 정확하게 어떤 것을 주는 건지 알 수 없다. 
	: ![](Pasted%20image%2020250110172426.png)
	: 어떤 모델을 선택하는 것이 옳은가? (초록색인지, 검정색인지) -> margin이 큰 모델을 선택하겠다. -> 각 점으로부터 거리가 큰 모델을 선택하겠다. ![](Pasted%20image%2020250110172549.png)
	: 초록색 선이 margin이 작은 모델
	: margin이 더 큰 모델을 더 견고하다고 표현하고 그걸 선택하는게 옳다. 

## 2. #SVM 
: 주어진 데이터를 두 class로 나누는 초평면(hyperplane)을 찾는 것. 
: 이 초평면은 데이터를 최대한 잘 구분할 수 있도록 설명되며, 이는 margin을 최대화하는 것을 뜻함.
: ![](Pasted%20image%2020250110173536.png)
: a^Tx0 +b를 1로 고정을 한 상태였을 때, a가 가장 작아졌을면 좋겠다 라는 식으로 조건을 바꾸어서 역으로 푸는 것을 SVM이라고 한다. 
: 즉, a^Tx0 +b의 margin이 1로 유지된 상태에서 분모에 해당하는 a의 크기가 가장 작아지면 결론적으로 margin의 값이 커지니까! 
![](Pasted%20image%2020250110173821.png)
: #QCQP (Quadratically Constrained Quadratic Program)
	: 2차 제약 조건(Quadratic Constraints)과 2차 목적 함수(Quadratic Objective Function)를 포함하는 최적화 문제

## 3. 데이터가 선형적으로 분리되지 않은 경우가 더 많음
: ![](Pasted%20image%2020250110174101.png)
: 이런 경우가 더 많음. 
: 근데 이런 경우도 SVM을 사용해서 풀고 싶잖아? 
=> #SlackVariable 을 추가하여 해결할 수 있다. 
![](Pasted%20image%2020250110174231.png)
: 올바르게 분류되면서 margin이 1이상이어야 한다는 것을 제약 조건으로 삼았다고 생각하면 됨. 
: 모든 점이 만족할 수 없다면, 각 점마다 제타i만큼의 패널티를 추가하여 만족할 수 없다면 그나마 조금 넘어라 라는 조건을 추가할 수 있다. 
: 제타가 0이면 가장 좋지. #HingeLoss
![](Pasted%20image%2020250110174603.png)

## 4. 데이터가 직선으로 분류하는 것이 불충분하다면? 
#kernel
![](Pasted%20image%2020250110174811.png): x1, x2, x1^2, x2^2를 넣어줌으로써 2차 타원의 형태를 표현할 수 있기 때문에, 더 잘 표현할 수 있게 된다. 
: overfitting이 발생 할 수 있다

# Part 5. Logistic Regression 
#LogisticRegression
: 이진 분류에서 벗어나 여러 클래스가 존재한다면 어떻게 해결할까? 

## 1.  Soft guess
#Softguess 
: ![](Pasted%20image%2020250110180510.png)
: 어떤 이미지에 대해서 이건 강아지야, 이건 고양이야 라고 나눌 수 있다면 -> hard guess 
: 강아지인 것 같기도, 고양이인 것 같기도 -> soft guess 
	: 이런 경우 억지로 하나를 고르게 하는 것보다, 강아지일 확률, 고양이일 확률을 나누는 것이 나중에 구별 가능하고도 연결되는 포인트가 된다. 
	: 확률로 나누고 나중에 사람한테 결정하라고 할 수도 있음. 
	
![](Pasted%20image%2020250110180828.png)
: 숫자 2개를 내뱉는 모델이 된다. ![](Pasted%20image%2020250110180933.png)
![](Pasted%20image%2020250110181104.png)
: #CrossEntropyLoss : 정답에 얼마나 가깝게 접근했냐 ![](Pasted%20image%2020250110181301.png)
: crosse entropy loss는 #KL 에서 유도가 되었음 
#Kullback-LeiblerDivergence , #RelativeEntropy: 2개의 확률분포가 주어질 때, 이 2개가 확률 분포가 얼마나 멀리 떨어져 있는가를 계산하는 확률 분포 사이의 거리를 측정하는 함수
	: ex) 비가 올 확률이 30%(p), 비가 오지 않을 확률 70%(q)라면 식이 저렇게 됨. 


![](Pasted%20image%2020250110181933.png)
: 데이터가 n개 주어져 있을때, 
: y가 -1일 확률과, 1일 확률을 로지스틱 함수를 이용해서 표현하는 함수 클래스를 정의한다. 
: Loss function : cross entropy를 이용해서 정답에 얼마나 높은 확률로, 혹은 낮은 확률로 예측했는가를 평가하는 형태로 손실을 계산하게 한다. 

![](Pasted%20image%2020250110182214.png)
![](Pasted%20image%2020250110182429.png)
![](Pasted%20image%2020250110182555.png)

## 2. Multiclass Classification
#MulticlassClassification 
![](Pasted%20image%2020250110183509.png)
: 강아지일 확률, 고양이일 확률, 비행기일 확률을 내뱉는 모델을 디자인할 수 있음. 
: 방법 : Linear 함수를 통과 -> Softmax 함수 통과(확률과 유사한 산출물을 내도록 함수를 설정)